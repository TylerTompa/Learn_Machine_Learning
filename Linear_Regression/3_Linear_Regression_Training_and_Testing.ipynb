{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression: Feature Scaling\n",
    "## Sources: \n",
    "1. <a href=\"https://pythonprogramming.net/training-testing-machine-learning-tutorial/\" target=\"_blank\">Python Programming: Regression - Training and Testing</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebooks, we learned what linear regression is, what features and labels are, and why as well as how to scale the features.  In this notebook, we will train and test our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Adj. Close  High_Low_Volatility_Percent  Daily_Percent_Change  Adj. Volume  \\\n",
      "0   50.322842                     8.441017              0.324968   44659000.0   \n",
      "1   54.322689                     8.537313              7.227007   22834300.0   \n",
      "2   54.869377                     4.062357             -1.227880   18256100.0   \n",
      "3   52.597363                     7.753210             -5.726357   15247300.0   \n",
      "4   53.164113                     3.966115              1.183658    9188600.0   \n",
      "\n",
      "    Forecast  \n",
      "0  69.078238  \n",
      "1  67.839414  \n",
      "2  68.912727  \n",
      "3  70.668146  \n",
      "4  71.219849  \n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "import os\n",
    "data_file_path = os.path.join(\"Data\",\"stock_data_features_and_label.csv\")\n",
    "\n",
    "stock_data_features_and_label = pd.read_csv(data_file_path)\n",
    "print(stock_data_features_and_label.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features\n",
    "X = np.array(stock_data_features_and_label.drop([\"Forecast\"], 1))\n",
    "\n",
    "# Define label\n",
    "y = np.array(stock_data_features_and_label[\"Forecast\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note!\n",
    "\n",
    "Recall that we engineered the label column- or the Forecast column- by shifting the values in the Adj. Close column up 35 values.  This would mean that the last 35 rows in the Forecast column have no value.  We will show this more clearly by looking at the last 37 rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Adj. Close  High_Low_Volatility_Percent  Daily_Percent_Change  \\\n",
      "3387     1119.20                     1.811604             -0.729098   \n",
      "3388     1068.76                     5.512236             -2.893850   \n",
      "3389     1084.43                     5.569849              4.879205   \n",
      "3390     1055.41                     3.025734             -2.724499   \n",
      "3391     1005.60                     5.851043             -5.120439   \n",
      "3392     1043.43                     5.488465              1.710726   \n",
      "3393     1054.56                     1.920631             -0.199684   \n",
      "3394     1054.14                     1.365911              0.394286   \n",
      "3395     1072.70                     2.445228              1.743304   \n",
      "3396     1091.36                     2.517733              0.730075   \n",
      "3397     1095.50                     1.535431              0.193894   \n",
      "3398     1103.59                     2.411927              0.991068   \n",
      "3399     1113.75                     2.590496              0.419259   \n",
      "3400     1109.90                     1.837760             -0.828292   \n",
      "3401     1128.09                     1.854859              0.842973   \n",
      "3402     1143.70                     1.315813              1.046066   \n",
      "3403     1117.51                     2.458833             -2.289936   \n",
      "3404     1103.92                     2.234814             -1.611408   \n",
      "3405     1071.41                     4.120717             -3.436559   \n",
      "3406     1084.14                     3.502490              2.472637   \n",
      "3407     1094.76                     2.696149              1.542486   \n",
      "3408     1100.90                     1.016903             -0.108883   \n",
      "3409     1115.04                     2.412126              2.033272   \n",
      "3410     1129.38                     1.274615              1.090226   \n",
      "3411     1160.84                     2.354777              1.872751   \n",
      "3412     1165.93                     1.635611              0.075533   \n",
      "3413     1139.91                     3.827882             -2.723945   \n",
      "3414     1148.89                     1.524051              0.269681   \n",
      "3415     1150.61                     2.363383              0.090469   \n",
      "3416     1134.42                     2.249505             -1.811572   \n",
      "3417     1100.07                     2.796349             -1.582630   \n",
      "3418     1095.80                     2.136878             -0.236708   \n",
      "3419     1094.00                     1.976619              0.130884   \n",
      "3420     1053.15                     3.265882             -2.487014   \n",
      "3421     1026.55                     4.089299             -2.360729   \n",
      "3422     1054.09                     4.818025              0.332191   \n",
      "3423     1006.94                     6.707965             -5.353887   \n",
      "\n",
      "      Adj. Volume  Forecast  \n",
      "3387    5798880.0   1054.09  \n",
      "3388    3742469.0   1006.94  \n",
      "3389    3732527.0       NaN  \n",
      "3390    2544683.0       NaN  \n",
      "3391    3067173.0       NaN  \n",
      "3392    4436032.0       NaN  \n",
      "3393    2796258.0       NaN  \n",
      "3394    1574121.0       NaN  \n",
      "3395    2029979.0       NaN  \n",
      "3396    1806206.0       NaN  \n",
      "3397    1971928.0       NaN  \n",
      "3398    1646405.0       NaN  \n",
      "3399    2024534.0       NaN  \n",
      "3400    1386115.0       NaN  \n",
      "3401    1234539.0       NaN  \n",
      "3402    1489118.0       NaN  \n",
      "3403    2094863.0       NaN  \n",
      "3404    2431023.0       NaN  \n",
      "3405    2766856.0       NaN  \n",
      "3406    2508145.0       NaN  \n",
      "3407    1432369.0       NaN  \n",
      "3408    1169068.0       NaN  \n",
      "3409    1537429.0       NaN  \n",
      "3410    1510478.0       NaN  \n",
      "3411    2070174.0       NaN  \n",
      "3412    2129297.0       NaN  \n",
      "3413    2129435.0       NaN  \n",
      "3414    2033697.0       NaN  \n",
      "3415    1623868.0       NaN  \n",
      "3416    2654602.0       NaN  \n",
      "3417    3076349.0       NaN  \n",
      "3418    2709310.0       NaN  \n",
      "3419    1990515.0       NaN  \n",
      "3420    3418154.0       NaN  \n",
      "3421    2413517.0       NaN  \n",
      "3422    3272409.0       NaN  \n",
      "3423    2940957.0       NaN  \n"
     ]
    }
   ],
   "source": [
    "# Preview last 35 columns of data\n",
    "print(stock_data_features_and_label.tail(37))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we should also adjust our features $X$ and label $y$ such that it excludes the last 35 values.  That is, we will only go up to the ($\\alpha - 1)^{th}$ value, where $\\alpha$ is the length of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of days out we want to forecast\n",
    "# In this case, want to forecast out 1% of the dataframe\n",
    "import math\n",
    "forecast_out = math.ceil(0.01*len(stock_data_features_and_label))\n",
    "\n",
    "# Only include values up until the row before the Forecast values become null\n",
    "# or rather, exclude the last 1% of values\n",
    "# Recall that when specifying a range,\n",
    "# Python excludes the last value\n",
    "X = X[:-forecast_out]\n",
    "y = y[:-forecast_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of features: 3389\n",
      "Length of label: 3389\n"
     ]
    }
   ],
   "source": [
    "# Confirm features and labels are the same length\n",
    "length_of_features = len(X)\n",
    "length_of_label = len(y)\n",
    "\n",
    "print(f\"Length of features: {length_of_features}\")\n",
    "print(f\"Length of label: {length_of_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing\n",
    "\n",
    "When building a machine learning model, you will usually split your data into training and testing sets.  The training set is passed into the classifier so that it can build the equation used to make predictions.  The testing set can then be used to measure the accuracy of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which classification algorithm we are using\n",
    "classifier = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit- or train- the classifier\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9788606958521906\n"
     ]
    }
   ],
   "source": [
    "# Print the score- or accuracy- of the classifier\n",
    "print(classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
