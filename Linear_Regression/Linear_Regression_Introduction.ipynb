{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Linear Regression\n",
    "## Sources: \n",
    "1. <a href=\"https://pythonprogramming.net/regression-introduction-machine-learning-tutorial/\">Python Programming, Data Analysis, Machine Learning, Practical Machine Learning with Python: Regression - Intro and Data</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fundamental technique in Machine Learning is <em>Linear Regression</em>.  The idea of linear regression is to find a <em>best-fit line</em> that is as close to as much of the data as possible, so that given an input value $x$, you can predict the output value $y$.  Recall that the equation of a line is $y=mx+b$.\n",
    "\n",
    "<img src=\"../Images/linear-regression-line.png\" alt=\"best-fit line\">\n",
    "Image source: [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import quandl, the data source we use\n",
    "import quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Open    High     Low    Close      Volume  Ex-Dividend  \\\n",
      "Date                                                                   \n",
      "2004-08-19  100.01  104.06   95.96  100.335  44659000.0          0.0   \n",
      "2004-08-20  101.01  109.08  100.50  108.310  22834300.0          0.0   \n",
      "2004-08-23  110.76  113.48  109.05  109.400  18256100.0          0.0   \n",
      "2004-08-24  111.24  111.60  103.57  104.870  15247300.0          0.0   \n",
      "2004-08-25  104.76  108.00  103.88  106.000   9188600.0          0.0   \n",
      "\n",
      "            Split Ratio  Adj. Open  Adj. High   Adj. Low  Adj. Close  \\\n",
      "Date                                                                   \n",
      "2004-08-19          1.0  50.159839  52.191109  48.128568   50.322842   \n",
      "2004-08-20          1.0  50.661387  54.708881  50.405597   54.322689   \n",
      "2004-08-23          1.0  55.551482  56.915693  54.693835   54.869377   \n",
      "2004-08-24          1.0  55.792225  55.972783  51.945350   52.597363   \n",
      "2004-08-25          1.0  52.542193  54.167209  52.100830   53.164113   \n",
      "\n",
      "            Adj. Volume  \n",
      "Date                     \n",
      "2004-08-19   44659000.0  \n",
      "2004-08-20   22834300.0  \n",
      "2004-08-23   18256100.0  \n",
      "2004-08-24   15247300.0  \n",
      "2004-08-25    9188600.0  \n"
     ]
    }
   ],
   "source": [
    "# Use quandl to get stock data for GOOGL\n",
    "googl_stock_data = quandl.get(\"WIKI/GOOGL\")\n",
    "\n",
    "# preview data for GOOGL\n",
    "print(googl_stock_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open           0\n",
      "High           0\n",
      "Low            0\n",
      "Close          0\n",
      "Volume         0\n",
      "Ex-Dividend    0\n",
      "Split Ratio    0\n",
      "Adj. Open      0\n",
      "Adj. High      0\n",
      "Adj. Low       0\n",
      "Adj. Close     0\n",
      "Adj. Volume    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(googl_stock_data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often when working with machine learning, we have more data than we need; once we get to the \"training\" part, this can cause issues, as too much unnecessary data could just confuse or bias the model.\n",
    "\n",
    "In this case, we don't need both regular prices as well as adjusted prices.  We will proceed with only the adjusted prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Adj. Open  Adj. Close  Adj. High   Adj. Low  Adj. Volume\n",
      "Date                                                                \n",
      "2004-08-19  50.159839   50.322842  52.191109  48.128568   44659000.0\n",
      "2004-08-20  50.661387   54.322689  54.708881  50.405597   22834300.0\n",
      "2004-08-23  55.551482   54.869377  56.915693  54.693835   18256100.0\n",
      "2004-08-24  55.792225   52.597363  55.972783  51.945350   15247300.0\n",
      "2004-08-25  52.542193   53.164113  54.167209  52.100830    9188600.0\n"
     ]
    }
   ],
   "source": [
    "# Create new dataframe with only relevant data\n",
    "googl_stock_data_meaningful_data = googl_stock_data[[\"Adj. Open\", \\\n",
    "                                                   \"Adj. Close\", \\\n",
    "                                                   \"Adj. High\", \\\n",
    "                                                   \"Adj. Low\", \\\n",
    "                                                   \"Adj. Volume\"]]\n",
    "# Preview new dataframe with only relevant data\n",
    "print(googl_stock_data_meaningful_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very important thing to keep in mind when working with data is how meaningful your data is.  Having a large abundance of data is not necessarily a good thing, if it's not meaningful data.\n",
    "\n",
    "In this case, we have open and close price, which we will use to calculate daily percent change, as well as high and low price, which we will use to calculate daily high-low volatilty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Adj. Open  Adj. Close  Adj. High   Adj. Low  Adj. Volume  \\\n",
      "Date                                                                   \n",
      "2004-08-19  50.159839   50.322842  52.191109  48.128568   44659000.0   \n",
      "2004-08-20  50.661387   54.322689  54.708881  50.405597   22834300.0   \n",
      "2004-08-23  55.551482   54.869377  56.915693  54.693835   18256100.0   \n",
      "2004-08-24  55.792225   52.597363  55.972783  51.945350   15247300.0   \n",
      "2004-08-25  52.542193   53.164113  54.167209  52.100830    9188600.0   \n",
      "\n",
      "            Daily_Percent_Change  High_Low_Volatility_Percent  \n",
      "Date                                                           \n",
      "2004-08-19              0.324968                     8.441017  \n",
      "2004-08-20              7.227007                     8.537313  \n",
      "2004-08-23             -1.227880                     4.062357  \n",
      "2004-08-24             -5.726357                     7.753210  \n",
      "2004-08-25              1.183658                     3.966115  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tyler\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\tyler\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Calculuate daily percent change and make new column therefrom\n",
    "googl_stock_data_meaningful_data[\"Daily_Percent_Change\"] = \\\n",
    "                                                         ((googl_stock_data_meaningful_data[\"Adj. Close\"] \\\n",
    "                                                          - googl_stock_data_meaningful_data[\"Adj. Open\"]) \\\n",
    "                                                          / googl_stock_data_meaningful_data[\"Adj. Open\"]\n",
    "                                                          * 100)\n",
    "# Calculate high-low volatility percent and make new column therefrom\n",
    "googl_stock_data_meaningful_data[\"High_Low_Volatility_Percent\"] = \\\n",
    "                                                         ((googl_stock_data_meaningful_data[\"Adj. High\"] \\\n",
    "                                                          - googl_stock_data_meaningful_data[\"Adj. Low\"]) \\\n",
    "                                                          / googl_stock_data_meaningful_data[\"Adj. Low\"] \\\n",
    "                                                          * 100)\n",
    "# Preview dataframe now with more meaningful columns\n",
    "print(googl_stock_data_meaningful_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
